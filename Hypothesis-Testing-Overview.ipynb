{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Hypothesis Testing\n",
    "\n",
    "\n",
    "![Types of Stats](Stats-types.jpg)\n",
    "\n",
    "\n",
    "![descriptive-and-inferential-statistics](descriptive-and-inferential-statistics.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "We will use some built-in datasets from the pydataset library to review and explore some concepts. \n",
    "\n",
    "1. How distributions help us make inferernces\n",
    "\n",
    "2. Sample vs. population\n",
    "\n",
    "3. Asking interesting and relevant questions of your data\n",
    "\n",
    "4. Ways to answer questions\n",
    "\n",
    "5. How Hypothesis testing helps us make inferences (In this lesson we will introduce some broad concepts related to hypothesis testing, and in future lessons we will look at examples of 3 types of hypothesis tests in detail.)\n",
    "\n",
    "6. Key terms in hypothesis testing\n",
    "\n",
    "\n",
    "In doing all of this, we will also practice transforming datasets using python, understanding the structure of an existing dataset and how it may differ from what you want, how to define an observation vs. a row. \n",
    "\n",
    "So, let's get to it...\n",
    "\n",
    "__________________________________________________\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "First, we need data. In this lesson, instead of generating random data, we will use data from the pydataset library which contains 756 datasets available for use. \n",
    "As you will soon get used to, every data science project starts with prject planning followed by acquiring and preparing data, a.k.a. wrangling the data. One non-negotiable to having prepared data ready to explore is that each row represents an observation. Let's take an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d80996bd3e46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Using open datasets from pydataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydataset'"
     ]
    }
   ],
   "source": [
    "# Using open datasets from pydataset\n",
    "from pydataset import data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at available datasets \n",
    "data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the **HairEyeColor** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the row that contains the HairEyeColor dataset using iloc\n",
    "data().iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, We are told this dataset contains information about Hair and Eye color of a group of statistics students. \n",
    "Let's take a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store that data in a dataframe named df\n",
    "df = data('HairEyeColor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the numbers of rows and columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the first 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** \n",
    "\n",
    "What do you notice about the structure of this dataset?\n",
    "\n",
    "\n",
    "_____________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** \n",
    "\n",
    "If we take a look at a single row, what/who does it represent? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code to view a single row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________\n",
    "\n",
    "\n",
    "Our data has been aggregated! UGH! I *strongly dislike* starting with aggregated data, as a data scientist :=| It limits what I can find out. \n",
    "\n",
    "I want my data in the form where one row represents one observation. \n",
    "\n",
    "\n",
    "**Question:**\n",
    "\n",
    "In this scenario, based on the description of the dataset, a single observation should be what?  \n",
    "\n",
    "\n",
    "___________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's stretch this data out, so that each row represents a single student. \n",
    "\n",
    "To do so, we need to ... \n",
    "\n",
    "1. repeat each row by the frequency. \n",
    "\n",
    "2. remove the frequency column. \n",
    "\n",
    "We should end up the same number of rows as the total number of students represented, because...\n",
    "\n",
    "EACH ROW IS AN OBSERVATION AND EACH OBSERVATION IS A STUDENT. \n",
    "\n",
    "\n",
    "**Question:**\n",
    "\n",
    "So, how can I compute how many rows we will end up with? Or how many students were surveyed?\n",
    "\n",
    "If you need to take another peek at the data, go for it! `df.head()` is a quick and easy way. \n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code to compute how many students are represented in this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, so we are looking to end up with that many rows\n",
    "\n",
    "___________________________________________\n",
    "_______________________________________\n",
    "\n",
    "To get there, we will want to repeat each combination of `Hair`, `Eye`, & `Sex` the number of times represented in the `Freq` field. We can get there in the following way:  \n",
    "\n",
    "1. Create a single column that concatenates Hair, Eye & Sex\n",
    "\n",
    "2. For the first unique combination of Hair, Eye & Sex, i.e. the first row which is Black, Brown, and Male, create a list that repeats that combination 32 times, which is the `Freq` value. \n",
    "\n",
    "3. We want to do that for each row, so once we made it work for one, we will put it in a loop to work for all. \n",
    "\n",
    "_______________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Create a single column that concatenates Hair, Eye & Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating using '+' with strings\n",
    "\n",
    "df['traits'] = df.Hair + \", \" + df.Eye + \", \" + df.Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Create a list from the first row, which is Black, Brown, and Male, that repeats that combination 32 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the first row\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract what we want to repeat: the contents in the traits column\n",
    "traits = df.traits.iloc[0]\n",
    "traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract how many times we want to repeat...the value in the Freq column\n",
    "freq = df.Freq.iloc[0]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.repeat to repeat `trait` `Freq` times.\n",
    "traits_by_freq = np.repeat(df.traits.iloc[0], df.Freq.iloc[0])\n",
    "traits_by_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we need that array to be a list\n",
    "row1_observations = list(traits_by_freq)\n",
    "row1_observations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling that all together...\n",
    "\n",
    "row1_obs = list(np.repeat(df.traits.iloc[0], df.Freq.iloc[0]))\n",
    "\n",
    "print(\"First original row:\\n\", df.iloc[0])\n",
    "print(\"\\nNumber of observations/students:\\n\",len(row1_obs))\n",
    "print(\"\\nFirst 5 observations:\\n\", row1_obs[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. We want to do that for each row, so let's make sure it works for another row, concatenate them, and then write a loop to do that for all the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row2_obs = list(np.repeat(df.traits.iloc[1], df.Freq.iloc[1]))\n",
    "\n",
    "\n",
    "print(\"Second original row:\\n\", df.iloc[1])\n",
    "print(\"\\nNumber of observations/students:\\n\",len(row2_obs))\n",
    "print(\"\\nFirst 5 observations:\\n\", row2_obs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate observations from the first original row to the observations from the second\n",
    "# start with an empty list to hold all observations\n",
    "obs = []\n",
    "# add the first rows observations to the list\n",
    "obs += row1_obs\n",
    "\n",
    "len(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the second row's observations to the list\n",
    "obs += row2_obs\n",
    "\n",
    "len(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the loop \n",
    "obs = []\n",
    "\n",
    "# go through all 32 rows\n",
    "for i in range(len(df)):\n",
    "    obs += list(np.repeat(df.traits.iloc[i], df.Freq.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from the list. \n",
    "obs_df = pd.DataFrame({'traits': obs})\n",
    "obs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the traits at the comma into 3 different columns (n=-1 means ALL, so I could put 3 here since I know there are 3)\n",
    "# expand = True means return to me a dataframe\n",
    "obs_df = obs_df[\"traits\"].str.split(\", \", n = -1, expand = True)\n",
    "obs_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give columns meaningful names\n",
    "obs_df.columns = ['hair', 'eye', 'sex']\n",
    "obs_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a list from the second row and test out concatenating these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the 2nd row `traits` the 2nd row `Freq` number of times, and turn that into a list\n",
    "\n",
    "row2_observations = list(np.repeat(df.traits.iloc[1], df.Freq.iloc[1]))\n",
    "row2_observations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list, observations, to hold those from row1 and row2 lists \n",
    "observations = []\n",
    "\n",
    "# add row1_observations to the list\n",
    "observations += row1_observations\n",
    "observations[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row2_observations to the list\n",
    "observations += row2_observations\n",
    "observations[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we know:\n",
    "\n",
    "1. start with an empty list:  `observations = []`\n",
    "\n",
    "2. in the loop will be: `observations += list(np.repeat(df.traits.iloc[i], df.Freq.iloc[i]))`\n",
    "\n",
    "3. **Question:** What values are we going to loop through? `for i in ....`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________\n",
    "__________________________________________________\n",
    "\n",
    "\n",
    "2. Sample vs. Population\n",
    "\n",
    "\n",
    "According to heffingtons, the estimated population proportion of blue eys in the U.S. is 27%\n",
    "This proportion from our sample seems much higher than expected! \n",
    "\n",
    "https://heffingtons.com/interesting-facts-about-eye-color/\n",
    "\n",
    "- Brown Eyes: 45%\n",
    "\n",
    "- Blue Eyes: 27%\n",
    "\n",
    "- Hazel Eyes: 18% (Note: Hazel eyes consist of shades of brown and green.)\n",
    "\n",
    "- Green Eyes: 9%\n",
    "\n",
    "- Other: 1%\n",
    "\n",
    "\n",
    "**Question:**\n",
    "\n",
    "What are some possible reasons why? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This dataset claims to be a sample of statistics students. \n",
    "\n",
    "**Questions:**\n",
    "\n",
    "So is the population all statistics students? \n",
    "\n",
    "Across the world? \n",
    "\n",
    "All ages? \n",
    "\n",
    "Is it a representative sample of the population of all statistics students across the world of all ages? \n",
    "\n",
    "Or is it representative sample of the population of all people across the world of all ages? \n",
    "\n",
    "Or is it representative sample of the population of all people in the US of all ages? \n",
    "\n",
    "Or is it representative sample of the population of all statistics students in the US of all ages? \n",
    "\n",
    "Or is it representative sample of the population of all statistics students in the US of all ages? \n",
    "\n",
    "Or ...\n",
    "\n",
    "\n",
    "_________________________________________________________\n",
    "\n",
    "\n",
    "Hypothesis testing can help us answer these questions as well as many others. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to answer questions that we will practice throughout your time here:\n",
    "\n",
    "1. data visualization \n",
    "\n",
    "2. hypothesis testing\n",
    "\n",
    "3. machine learning\n",
    "\n",
    "4. Saying I don't know, but I will try to find out. \n",
    "\n",
    "\n",
    "Ways that we will not cover:\n",
    "\n",
    "1. pulling it out of your arse\n",
    "\n",
    "2. using statistics to give you the answer you want. \n",
    "\n",
    "3. selecting biased samples to prove your point. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
